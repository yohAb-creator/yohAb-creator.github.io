<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Topological Prompt Distillation | The Bridge: A Research Focused Blog</title>
<meta name="keywords" content="research, Machine Learning, Topological Data Analysis">
<meta name="description" content="Introduction: Asking the Right Question

In order to receive an answer, one must first ask a question. This concept also holds when it comes to our interaction with Large Language Models(LLMs)— to receive a desirable answer, we must first provide a prompt that is adequately crafted. The prompt needs to contain just enough information to guide the LLM towards the correct solution, while also avoiding extraneous information that might derail the LLM&rsquo;s answer.
Crafting a perfect prompt might be challenging due to various reasons, including a prompt encapsulating some other text. A solution for this problem is to distill existing prompts down to their most critical components, a method referred to as prompt compression.">
<meta name="author" content="map[education:map[courses:[map[course:BA in Mathematics and Physics institution:College of Wooster year:2024]]] interests:[Algebraic Topology Quantum Mechanics Multiversal Theory Advanced Computational Methods Non-Euclidean Geometry] name:Yohannes role:Researcher social:[map[icon:envelope icon_pack:fas link:mailto:yohannesabateneh@gmail.com] map[icon:twitter icon_pack:fab link:https://twitter.com/username] map[icon:google-scholar icon_pack:ai link:https://scholar.google.com/citations?user=username] map[icon:github icon_pack:fab link:https://github.com/yohAb-creator]]]">
<link rel="canonical" href="https://yohab-creator.github.io/projects/topological_distillation/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://yohab-creator.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://yohab-creator.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://yohab-creator.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://yohab-creator.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://yohab-creator.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://yohab-creator.github.io/projects/topological_distillation/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://yohab-creator.github.io/projects/topological_distillation/">
  <meta property="og:site_name" content="The Bridge: A Research Focused Blog">
  <meta property="og:title" content="Topological Prompt Distillation">
  <meta property="og:description" content="Introduction: Asking the Right Question In order to receive an answer, one must first ask a question. This concept also holds when it comes to our interaction with Large Language Models(LLMs)— to receive a desirable answer, we must first provide a prompt that is adequately crafted. The prompt needs to contain just enough information to guide the LLM towards the correct solution, while also avoiding extraneous information that might derail the LLM’s answer. Crafting a perfect prompt might be challenging due to various reasons, including a prompt encapsulating some other text. A solution for this problem is to distill existing prompts down to their most critical components, a method referred to as prompt compression.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="projects">
    <meta property="article:published_time" content="2025-06-10T18:42:14-05:00">
    <meta property="article:modified_time" content="2025-06-10T18:42:14-05:00">
    <meta property="article:tag" content="Research">
    <meta property="article:tag" content="Machine Learning">
    <meta property="article:tag" content="Topological Data Analysis">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Topological Prompt Distillation">
<meta name="twitter:description" content="Introduction: Asking the Right Question

In order to receive an answer, one must first ask a question. This concept also holds when it comes to our interaction with Large Language Models(LLMs)— to receive a desirable answer, we must first provide a prompt that is adequately crafted. The prompt needs to contain just enough information to guide the LLM towards the correct solution, while also avoiding extraneous information that might derail the LLM&rsquo;s answer.
Crafting a perfect prompt might be challenging due to various reasons, including a prompt encapsulating some other text. A solution for this problem is to distill existing prompts down to their most critical components, a method referred to as prompt compression.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "https://yohab-creator.github.io/projects/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Topological Prompt Distillation",
      "item": "https://yohab-creator.github.io/projects/topological_distillation/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Topological Prompt Distillation",
  "name": "Topological Prompt Distillation",
  "description": "Introduction: Asking the Right Question In order to receive an answer, one must first ask a question. This concept also holds when it comes to our interaction with Large Language Models(LLMs)— to receive a desirable answer, we must first provide a prompt that is adequately crafted. The prompt needs to contain just enough information to guide the LLM towards the correct solution, while also avoiding extraneous information that might derail the LLM\u0026rsquo;s answer. Crafting a perfect prompt might be challenging due to various reasons, including a prompt encapsulating some other text. A solution for this problem is to distill existing prompts down to their most critical components, a method referred to as prompt compression.\n",
  "keywords": [
    "research", "Machine Learning", "Topological Data Analysis"
  ],
  "articleBody": "Introduction: Asking the Right Question In order to receive an answer, one must first ask a question. This concept also holds when it comes to our interaction with Large Language Models(LLMs)— to receive a desirable answer, we must first provide a prompt that is adequately crafted. The prompt needs to contain just enough information to guide the LLM towards the correct solution, while also avoiding extraneous information that might derail the LLM’s answer. Crafting a perfect prompt might be challenging due to various reasons, including a prompt encapsulating some other text. A solution for this problem is to distill existing prompts down to their most critical components, a method referred to as prompt compression.\nMethodology: Journey from Text to Structure Semantic Similarity The first step in the journey involved in changing a prompt into a structured instruction is to filter redundant sentences through the use of semantic similarity. The way I did this was through the use of cosine similarity on the embeddings of the sentences. We start by considering a single sentence embedding and appending it to an empty list. As we iteratively go through the other sentences, we check the similarity between them and the other embeddings contained in the list. Sentence embeddings with cosine similarity less than some threshold value are appended to the list, while embeddings with a similarity score higher than the threshold are discarded.\nSemantic Significance The next step is to prioritize sentences based on semantic significance. As the area I am considering is primarily competitive programming, I first initialize a dictionary composed of keys corresponding to the input, the operation, and the goal. The corresponding values for these keys include a range of terms common in competitive programming. The sentences are assigned scores based on how many relevant terms they contain and the frequency with which the words occur. Then, both the sentences and the sentence embeddings are sorted in their respective lists according to their scores.\nPrompt Distillation with Topological Data Analysis(TDA) Now comes the final leg of the journey. Presented with a prompt, we first split it into separate sentences. The sentences are then embedded into a vector as discussed previously. Since the more similar sentences are, the higher their cosine similarity will be(with a maximum score of 1), we can subtract the cosine similarity from 1 to create a notion of distance—more similar sentences lie closer together. Using this distance as a basis, we create a Vietoris-Rips Complex Filtration and track the first homology group. Then, 1-cycles that last above a certain threshold of “time” are taken to be persistent cycles. The persistent cycles are then used to group the sentences making up the prompts into clusters based on which sentences belong to which persistent 1-cycles. Constraint sentences are determined through the presence of some common constraint words. In the case of a cluster containing multiple constraint sentences, only one constraint is picked as the others would just be redundant. Once we identify and make sure that the question and input sentences are included, we combine the sentences that passed through the distillation. The combined sentences are then passed through the semantic similarity filter to remove duplicates.\n",
  "wordCount" : "527",
  "inLanguage": "en",
  "datePublished": "2025-06-10T18:42:14-05:00",
  "dateModified": "2025-06-10T18:42:14-05:00",
  "author":{
    "@type": "Person",
    "name": {"education":{"courses":[{"course":"BA in Mathematics and Physics","institution":"College of Wooster","year":2024}]},"interests":["Algebraic Topology","Quantum Mechanics","Multiversal Theory","Advanced Computational Methods","Non-Euclidean Geometry"],"name":"Yohannes","role":"Researcher","social":[{"icon":"envelope","icon_pack":"fas","link":"mailto:yohannesabateneh@gmail.com"},{"icon":"twitter","icon_pack":"fab","link":"https://twitter.com/username"},{"icon":"google-scholar","icon_pack":"ai","link":"https://scholar.google.com/citations?user=username"},{"icon":"github","icon_pack":"fab","link":"https://github.com/yohAb-creator"}]}
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yohab-creator.github.io/projects/topological_distillation/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "The Bridge: A Research Focused Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yohab-creator.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://yohab-creator.github.io/" accesskey="h" title="The Bridge: A Research Focused Blog (Alt + H)">The Bridge: A Research Focused Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://yohab-creator.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://yohab-creator.github.io/projects/" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://yohab-creator.github.io/publications/" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="https://yohab-creator.github.io/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://yohab-creator.github.io/contact/" title="Contact">
                    <span>Contact</span>
                </a>
            </li>
            <li>
                <a href="https://yohab-creator.github.io/about/" title="About Me">
                    <span>About Me</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article>

  

  <h1>Topological Prompt Distillation</h1>

  <p>Jun 10, 2025</p>

  <p>By Yohannes (Researcher)</p>


  



  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">

  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script>

  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"></script>

  <script>

    document.addEventListener("DOMContentLoaded", function() {

      renderMathInElement(document.body, {

        delimiters: [

          {left: "$$", right: "$$", display: true},

          {left: "\\[", right: "\\]", display: true}, 

          {left: "$", right: "$", display: false},

          {left: "\\(", right: "\\)", display: false} 

        ]

      });

    });

  </script>




  <h1 id="introduction-asking-the-right-question">Introduction: Asking the Right Question</h1>
<hr>
<p>In order to receive an answer, one must first ask a question. This concept also holds when it comes to our interaction with Large Language Models(LLMs)— to receive a desirable answer, we must first provide a prompt that is adequately crafted. The prompt needs to contain just enough information to guide the LLM towards the correct solution, while also avoiding extraneous information that might derail the LLM&rsquo;s answer.
Crafting a perfect prompt might be challenging due to various reasons, including a prompt encapsulating some other text. A solution for this problem is to distill existing prompts down to their most critical components, a method referred to as prompt compression.</p>
<h1 id="methodology-journey-from-text-to-structure">Methodology: Journey from Text to Structure</h1>
<hr>
<h2 id="semantic-similarity">Semantic Similarity</h2>
<p>The first step in the journey involved in changing a prompt into a structured instruction is to filter redundant sentences through the use of semantic similarity. The way I did this was through the use of cosine similarity on the embeddings of the sentences. We start by considering a single sentence embedding and appending it to an empty list. As we iteratively go through the other sentences, we check the similarity between them and the other embeddings contained in the list. Sentence embeddings with cosine similarity less than some threshold value are appended to the list, while embeddings with a similarity score higher than the threshold are discarded.</p>
<h2 id="semantic-significance">Semantic Significance</h2>
<p>The next step is to prioritize sentences based on semantic significance. As the area I am considering is primarily competitive programming, I first initialize a dictionary composed of keys corresponding to the input, the operation, and the goal. The corresponding values for these keys include a range of terms common in competitive programming. The sentences are assigned scores based on how many relevant terms they contain and the frequency with which the words occur. Then, both the sentences and the sentence embeddings are sorted in their respective lists according to their scores.</p>
<h2 id="prompt-distillation-with-topological-data-analysistda">Prompt Distillation with Topological Data Analysis(TDA)</h2>
<p>Now comes the final leg of the journey. Presented with a prompt, we first split it into separate sentences. The sentences are then embedded into a vector as discussed previously. Since the more similar sentences are, the higher their cosine similarity will be(with a maximum score of 1), we can subtract the cosine similarity from 1 to create a notion of distance—more similar sentences lie closer together. Using this distance as a basis, we create a Vietoris-Rips Complex Filtration and track the first homology group. Then, 1-cycles that last above a certain threshold of &ldquo;time&rdquo; are taken to be persistent cycles. <br>
The persistent cycles are then used to group the sentences making up the prompts into clusters based on which sentences belong to which persistent 1-cycles. Constraint sentences are determined through the presence of some common constraint words. In the case of a cluster containing multiple constraint sentences, only one constraint is picked as the others would just be redundant. Once we identify and make sure that the question and input sentences are included, we combine the sentences that passed through the distillation. The combined sentences are then passed through the semantic similarity filter to remove duplicates.</p>
 

</article>


    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://yohab-creator.github.io/">The Bridge: A Research Focused Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
